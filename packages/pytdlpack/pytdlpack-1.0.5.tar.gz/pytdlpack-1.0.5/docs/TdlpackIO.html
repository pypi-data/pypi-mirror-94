<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>TdlpackIO API documentation</title>
<meta name="description" content="TdlpackIO is a pure Python implementation for performing IO with TDLPACK sequential files
(i.e. Fortran unformatted files).
Instead of using Fortran â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>TdlpackIO</code></h1>
</header>
<section id="section-intro">
<p>TdlpackIO is a pure Python implementation for performing IO with TDLPACK sequential files
(i.e. Fortran unformatted files).
Instead of using Fortran for perform IO, we are using
Python builtins.open() in binary mode.
This allows us to perform stream-based IO for TDLPACK
files.
When a file is opened for reading, its contents (TDLPACK records) are automatically
indexed and stored in a dictionary.
The dictionary stores the byte offset the data record;
the size of the data record; date and lead time; and MOS-2000 ID.</p>
<p>This indexing allow the user to access a TDLPACK sequential file in a random-access nature.
For example if a users wants to read the 500th record in the file, the first 499 records in
their entirety do not need to be read.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
TdlpackIO is a pure Python implementation for performing IO with TDLPACK sequential files
(i.e. Fortran unformatted files).  Instead of using Fortran for perform IO, we are using
Python builtins.open() in binary mode.  This allows us to perform stream-based IO for TDLPACK
files.  When a file is opened for reading, its contents (TDLPACK records) are automatically
indexed and stored in a dictionary.  The dictionary stores the byte offset the data record;
the size of the data record; date and lead time; and MOS-2000 ID.

This indexing allow the user to access a TDLPACK sequential file in a random-access nature.
For example if a users wants to read the 500th record in the file, the first 499 records in
their entirety do not need to be read.
&#34;&#34;&#34;
import logging
import numpy as np
import os
import pdb
import pytdlpack
import struct
import sys  
import warnings

__version__ = pytdlpack.__version__ # Share the version number

_IS_PYTHON3 = sys.version_info.major &gt;= 3

if _IS_PYTHON3:
    import builtins
else:
    import __builtin__ as builtins

ONE_MB = 1024 ** 3

class open(object):
    def __init__(self,filename,mode=&#39;r&#39;):
        &#34;&#34;&#34;
        Class Constructor

        Parameters
        ----------

        **`filename : str`**

        File name.

        **`mode : str, optional, default = &#39;r&#39;`**

        File handle mode.  The default is open for reading (&#39;r&#39;).
        &#34;&#34;&#34;
        if mode == &#39;r&#39; or mode == &#39;w&#39;:
            mode = mode+&#39;b&#39;
        elif mode == &#39;a&#39;:
            mode = &#39;wb&#39;
        self._filehandle = builtins.open(filename,mode=mode,buffering=ONE_MB)
        self._hasindex = False
        self._index = {}
        self.mode = mode
        self.name = os.path.abspath(filename)
        self.records = 0
        self.recordnumber = 0
        self.size = os.path.getsize(self.name)
        # Perform indexing on read
        if &#39;r&#39; in self.mode:
            self._get_index()

    def __enter__(self):
        &#34;&#34;&#34;
        &#34;&#34;&#34;
        return self

    def __exit__(self,atype,value,traceback):
        &#34;&#34;&#34;
        &#34;&#34;&#34;
        self.close()

    def __iter__(self):
        &#34;&#34;&#34;
        &#34;&#34;&#34;
        return self

    def __next__(self):
        &#34;&#34;&#34;
        &#34;&#34;&#34;
        if self.recordnumber &lt; self.records:
            return self.read(1)[0]
        else:
            raise StopIteration

    def __repr__(self):
        &#34;&#34;&#34;
        &#34;&#34;&#34;
        strings = []
        keys = self.__dict__.keys()
        for k in keys:
            if not k.startswith(&#39;_&#39;):
                strings.append(&#39;%s = %s\n&#39;%(k,self.__dict__[k]))
        return &#39;&#39;.join(strings)

    def __getitem__(self,key):
        &#34;&#34;&#34;
        &#34;&#34;&#34;
        if isinstance(key,slice):
            beg, end, inc = key.indices(self.records)
            self.seek(beg)
            return [self.record(i+1) for i in range(beg,end,inc)]
        elif isinstance(key,int):
            if key == 0: return None
            self.seek(key)
            return self.record(key)
        else:
            raise KeyError(&#39;Key must be an integer record number or a slice&#39;)

    def _get_index(self):
        &#34;&#34;&#34;
        Perform indexing of data records.
        &#34;&#34;&#34;
        #pdb.set_trace()
        # Initialize index dictionary
        self._index[&#39;offset&#39;] = []
        self._index[&#39;size&#39;] = []
        self._index[&#39;type&#39;] = []
        self._index[&#39;date&#39;] = []
        self._index[&#39;lead&#39;] = []
        self._index[&#39;id1&#39;] = []
        self._index[&#39;id2&#39;] = []
        self._index[&#39;id3&#39;] = []
        self._index[&#39;id4&#39;] = []
        self._index[&#39;linked_station_id_record&#39;] = []
        _last_station_id_record = 0

        # Iterate
        while True:
            try:
                # First read 4-byte Fortran record header, then read the next
                # 44 bytes which provides enough information to catalog the
                # data record.
                pos = self._filehandle.tell()
                fortran_header = struct.unpack(&#39;&gt;i&#39;,self._filehandle.read(4))[0]
                if fortran_header &gt;= 44:
                    bytes_to_read = 44
                else:
                    bytes_to_read = fortran_header
                temp = np.frombuffer(self._filehandle.read(bytes_to_read),dtype=&#39;&gt;i4&#39;)
                _header = struct.unpack(&#39;&gt;4s&#39;,temp[2])[0].decode()

                # Check to first 4 bytes of the data record to determine the data
                # record type.
                if _header == &#39;PLDT&#39;:
                    # TDLPACK data record
                    self._index[&#39;size&#39;].append(temp[1])
                    self._index[&#39;type&#39;].append(&#39;data&#39;)
                    self._index[&#39;date&#39;].append(temp[6])
                    self._index[&#39;lead&#39;].append(int(str(temp[9])[-3:]))
                    self._index[&#39;id1&#39;].append(temp[7])
                    self._index[&#39;id2&#39;].append(temp[8])
                    self._index[&#39;id3&#39;].append(temp[9])
                    self._index[&#39;id4&#39;].append(temp[10])
                    self._index[&#39;linked_station_id_record&#39;].append(_last_station_id_record)
                else:
                    if temp[1] == 24 and temp[6] == 9999:
                        # Trailer record
                        self._index[&#39;size&#39;].append(temp[1])
                        self._index[&#39;type&#39;].append(&#39;trailer&#39;)
                        self._index[&#39;date&#39;].append(None)
                        self._index[&#39;lead&#39;].append(None)
                        self._index[&#39;id1&#39;].append(None)
                        self._index[&#39;id2&#39;].append(None)
                        self._index[&#39;id3&#39;].append(None)
                        self._index[&#39;id4&#39;].append(None)
                        self._index[&#39;linked_station_id_record&#39;].append(_last_station_id_record)
                    else:
                        # Station ID record
                        self._index[&#39;size&#39;].append(temp[1])
                        self._index[&#39;type&#39;].append(&#39;station&#39;)
                        self._index[&#39;date&#39;].append(None)
                        self._index[&#39;lead&#39;].append(None)
                        self._index[&#39;id1&#39;].append(400001000)
                        self._index[&#39;id2&#39;].append(0)  
                        self._index[&#39;id3&#39;].append(0)
                        self._index[&#39;id4&#39;].append(0)
                        self._index[&#39;linked_station_id_record&#39;].append(_last_station_id_record)

                # At this point we have successfully identified a TDLPACK record from
                # the file. Increment self.records and position the file pointer to
                # now read the Fortran trailer.
                self.records += 1 # Includes trailer records
                self._filehandle.seek(fortran_header-bytes_to_read,1)
                fortran_trailer = struct.unpack(&#39;&gt;i&#39;,self._filehandle.read(4))[0]

                # Check Fortran header and trailer for the record.
                if fortran_header != fortran_trailer:
                    raise IOError(&#39;Bad Fortran record.&#39;)

                # NOTE: The &#39;offset&#39; key contains the byte position in the file of where
                # data record begins. A value of 12 is added to consider a 4-byte Fortran
                # header, 4-byte &#34;trash&#34;, and 4-byte ioctet value (already) stored on index.
                self._index[&#39;offset&#39;].append(pos+12) # 4-byte header + 4-byte trash + 4-byte ioctet

                # Hold the record number of the last station ID record
                if self._index[&#39;type&#39;][-1] == &#39;station&#39;:
                    _last_station_id_record = self.records # This should be OK.

            except(struct.error):
                self._filehandle.seek(0)
                break

        self._hasindex = True
        self.dates = tuple(sorted(set(self._index[&#39;date&#39;])))
        self.leadtimes = tuple(sorted(set(self._index[&#39;lead&#39;])))

    def close(self):
        &#34;&#34;&#34;
        Close the file handle
        &#34;&#34;&#34;
        self._filehandle.close()

    def read(self,num=None,unpack=True):
        &#34;&#34;&#34;
        Read num records from the current position.
        &#34;&#34;&#34;
        #pdb.set_trace()
        recs = []
        if num == 0:
            return recs
        elif num == 1:
            reclist = [self.recordnumber+1]
        elif num &gt; 1:
            reclist = list(range(self.recordnumber+1,self.recordnumber+1+num))
        for n in reclist:
            nn = n-1 # Use this for the self._index referencing
            kwargs = {}
            self.seek(n)
            kwargs[&#39;ioctet&#39;] = self._index[&#39;size&#39;][nn]
            kwargs[&#39;ipack&#39;] = np.frombuffer(self._filehandle.read(self._index[&#39;size&#39;][nn]),dtype=&#39;&gt;i4&#39;)
            if self._index[&#39;type&#39;][nn] == &#39;data&#39;:
                kwargs[&#39;reference_date&#39;] = self._index[&#39;date&#39;][nn]
                rec = pytdlpack.TdlpackRecord(**kwargs)
                if unpack: rec.unpack()
                recs.append(rec)
            elif self._index[&#39;type&#39;][nn] == &#39;station&#39;:
                kwargs[&#39;ipack&#39;] = kwargs[&#39;ipack&#39;].byteswap()
                rec = pytdlpack.TdlpackStationRecord(**kwargs)
                if unpack: rec.unpack()
                recs.append(rec)
            elif self._index[&#39;type&#39;][nn] == &#39;trailer&#39;:
                recs.append(pytdlpack.TdlpackTrailerRecord(**kwargs))
            self.recordnumber = n
        return recs
    
    def record(self,rec,unpack=True):
        &#34;&#34;&#34;
        Read the N-th record.
        &#34;&#34;&#34;
        #pdb.set_trace()
        if rec is None:
            return None
        if rec &lt;= 0:
            warnings.warn(&#34;Record numbers begin at 1.&#34;) 
            return None
        elif rec &gt; self.records:
            warnings.warn(&#34;Not that many records in the file.&#34;)
            return None
        else:
            self.seek(rec) # Use the actual record number here.
            return self.read(1,unpack=unpack)[0]

    def seek(self,offset):
        &#34;&#34;&#34;
        Set the position within the file in units of data records.
        &#34;&#34;&#34;
        #pdb.set_trace()
        if self._hasindex:
            if offset == 0:
                self._filehandle.seek(self._index[&#39;offset&#39;][offset])
                self.recordnumber = offset
            elif offset &gt; 0:
                self._filehandle.seek(self._index[&#39;offset&#39;][offset-1])
                self.recordnumber = offset-1
    
    def fetch(self,date=None,id=None,lead=None,unpack=True):
        &#34;&#34;&#34;
        Fetch TDLPACK data record by means of date, lead time, id or any combination
        thereof.
        &#34;&#34;&#34;
        #pdb.set_trace()
        recs = []
        idx = None
        match_count = 0

        # Match by date.
        if type(date) is not list:
           if date is None:
               date = []
           else:
               date = [date]
        if len(date) &gt; 0: match_count += 1
        for d in date:
            if d is not None:
                if idx is None:
                    idx = np.where(np.array(self._index[&#39;date&#39;])==d)[0]
                else:
                    idx = np.concatenate((idx,np.where(np.array(self._index[&#39;date&#39;])==d)[0]))

        # Match by ID.
        if id is not None:
            # Test for type
            if type(id) is str:
                # Need all 4 words for now....
                id = [int(i) for i in list(filter(None,id.split(&#39; &#39;)))]
                print(id)
            # Match by MOS ID (all 4 words)
            match_count += 4
            allrecs = np.arange(self.records)
            # ID1
            if id[0] == -1:
                idx1 = allrecs
            elif id[0] &gt;= 0:
                idx1 = np.where(np.array(self._index[&#39;id1&#39;])==id[0])[0]
            # ID2
            if id[1] == -1:
                idx2 = allrecs
            elif id[1] &gt;= 0:
                idx2 = np.where(np.array(self._index[&#39;id2&#39;])==id[1])[0]
            # ID3
            if id[2] == -1:
                idx3 = allrecs
            elif id[2] &gt;= 0:
                idx3 = np.where(np.array(self._index[&#39;id3&#39;])==id[2])[0]
            # ID4
            if id[3] == -1:
                idx4 = allrecs
            elif id[3] &gt;= 0:
                idx4 = np.where(np.array(self._index[&#39;id4&#39;])==id[3])[0]

            if idx is not None:
                idx = np.concatenate((idx,idx1,idx2,idx3,idx4))
            else:
                idx = np.concatenate((idx1,idx2,idx3,idx4))

        # Match by lead times(s).
        if type(lead) is not list:
            if lead is None:
                lead = []
            else:
                lead = [lead]
        if len(lead) &gt; 0: match_count += 1
        for l in lead:
            if l is not None:
                if idx is None:
                    idx = np.where(np.array(self._index[&#39;lead&#39;])==l)[0]
                else:
                    idx = np.concatenate((idx,np.where(np.array(self._index[&#39;lead&#39;])==l)[0]))

        # Now determine the count of unique index values.  The count needs to match the
        # value of match_count.  Where this occurs, the index values are extracted.
        vals,cnts = np.unique(idx,return_counts=True)
        idx = vals[np.where(cnts==match_count)[0]]

        # Now we iterate over the matching index values and build the list of
        # records.
        for i in idx:
            recs.append(self.record(i+1,unpack=unpack))
        return recs
    
    def tell(self):
        &#34;&#34;&#34;
        Return the position in units of records.
        &#34;&#34;&#34;
        return self.recordnumber</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="TdlpackIO.open"><code class="flex name class">
<span>class <span class="ident">open</span></span>
<span>(</span><span>filename, mode='r')</span>
</code></dt>
<dd>
<div class="desc"><p>Class Constructor</p>
<h2 id="parameters">Parameters</h2>
<p><strong><code>filename : str</code></strong></p>
<p>File name.</p>
<p><strong><code>mode : str, optional, default = 'r'</code></strong></p>
<p>File handle mode.
The default is open for reading ('r').</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class open(object):
    def __init__(self,filename,mode=&#39;r&#39;):
        &#34;&#34;&#34;
        Class Constructor

        Parameters
        ----------

        **`filename : str`**

        File name.

        **`mode : str, optional, default = &#39;r&#39;`**

        File handle mode.  The default is open for reading (&#39;r&#39;).
        &#34;&#34;&#34;
        if mode == &#39;r&#39; or mode == &#39;w&#39;:
            mode = mode+&#39;b&#39;
        elif mode == &#39;a&#39;:
            mode = &#39;wb&#39;
        self._filehandle = builtins.open(filename,mode=mode,buffering=ONE_MB)
        self._hasindex = False
        self._index = {}
        self.mode = mode
        self.name = os.path.abspath(filename)
        self.records = 0
        self.recordnumber = 0
        self.size = os.path.getsize(self.name)
        # Perform indexing on read
        if &#39;r&#39; in self.mode:
            self._get_index()

    def __enter__(self):
        &#34;&#34;&#34;
        &#34;&#34;&#34;
        return self

    def __exit__(self,atype,value,traceback):
        &#34;&#34;&#34;
        &#34;&#34;&#34;
        self.close()

    def __iter__(self):
        &#34;&#34;&#34;
        &#34;&#34;&#34;
        return self

    def __next__(self):
        &#34;&#34;&#34;
        &#34;&#34;&#34;
        if self.recordnumber &lt; self.records:
            return self.read(1)[0]
        else:
            raise StopIteration

    def __repr__(self):
        &#34;&#34;&#34;
        &#34;&#34;&#34;
        strings = []
        keys = self.__dict__.keys()
        for k in keys:
            if not k.startswith(&#39;_&#39;):
                strings.append(&#39;%s = %s\n&#39;%(k,self.__dict__[k]))
        return &#39;&#39;.join(strings)

    def __getitem__(self,key):
        &#34;&#34;&#34;
        &#34;&#34;&#34;
        if isinstance(key,slice):
            beg, end, inc = key.indices(self.records)
            self.seek(beg)
            return [self.record(i+1) for i in range(beg,end,inc)]
        elif isinstance(key,int):
            if key == 0: return None
            self.seek(key)
            return self.record(key)
        else:
            raise KeyError(&#39;Key must be an integer record number or a slice&#39;)

    def _get_index(self):
        &#34;&#34;&#34;
        Perform indexing of data records.
        &#34;&#34;&#34;
        #pdb.set_trace()
        # Initialize index dictionary
        self._index[&#39;offset&#39;] = []
        self._index[&#39;size&#39;] = []
        self._index[&#39;type&#39;] = []
        self._index[&#39;date&#39;] = []
        self._index[&#39;lead&#39;] = []
        self._index[&#39;id1&#39;] = []
        self._index[&#39;id2&#39;] = []
        self._index[&#39;id3&#39;] = []
        self._index[&#39;id4&#39;] = []
        self._index[&#39;linked_station_id_record&#39;] = []
        _last_station_id_record = 0

        # Iterate
        while True:
            try:
                # First read 4-byte Fortran record header, then read the next
                # 44 bytes which provides enough information to catalog the
                # data record.
                pos = self._filehandle.tell()
                fortran_header = struct.unpack(&#39;&gt;i&#39;,self._filehandle.read(4))[0]
                if fortran_header &gt;= 44:
                    bytes_to_read = 44
                else:
                    bytes_to_read = fortran_header
                temp = np.frombuffer(self._filehandle.read(bytes_to_read),dtype=&#39;&gt;i4&#39;)
                _header = struct.unpack(&#39;&gt;4s&#39;,temp[2])[0].decode()

                # Check to first 4 bytes of the data record to determine the data
                # record type.
                if _header == &#39;PLDT&#39;:
                    # TDLPACK data record
                    self._index[&#39;size&#39;].append(temp[1])
                    self._index[&#39;type&#39;].append(&#39;data&#39;)
                    self._index[&#39;date&#39;].append(temp[6])
                    self._index[&#39;lead&#39;].append(int(str(temp[9])[-3:]))
                    self._index[&#39;id1&#39;].append(temp[7])
                    self._index[&#39;id2&#39;].append(temp[8])
                    self._index[&#39;id3&#39;].append(temp[9])
                    self._index[&#39;id4&#39;].append(temp[10])
                    self._index[&#39;linked_station_id_record&#39;].append(_last_station_id_record)
                else:
                    if temp[1] == 24 and temp[6] == 9999:
                        # Trailer record
                        self._index[&#39;size&#39;].append(temp[1])
                        self._index[&#39;type&#39;].append(&#39;trailer&#39;)
                        self._index[&#39;date&#39;].append(None)
                        self._index[&#39;lead&#39;].append(None)
                        self._index[&#39;id1&#39;].append(None)
                        self._index[&#39;id2&#39;].append(None)
                        self._index[&#39;id3&#39;].append(None)
                        self._index[&#39;id4&#39;].append(None)
                        self._index[&#39;linked_station_id_record&#39;].append(_last_station_id_record)
                    else:
                        # Station ID record
                        self._index[&#39;size&#39;].append(temp[1])
                        self._index[&#39;type&#39;].append(&#39;station&#39;)
                        self._index[&#39;date&#39;].append(None)
                        self._index[&#39;lead&#39;].append(None)
                        self._index[&#39;id1&#39;].append(400001000)
                        self._index[&#39;id2&#39;].append(0)  
                        self._index[&#39;id3&#39;].append(0)
                        self._index[&#39;id4&#39;].append(0)
                        self._index[&#39;linked_station_id_record&#39;].append(_last_station_id_record)

                # At this point we have successfully identified a TDLPACK record from
                # the file. Increment self.records and position the file pointer to
                # now read the Fortran trailer.
                self.records += 1 # Includes trailer records
                self._filehandle.seek(fortran_header-bytes_to_read,1)
                fortran_trailer = struct.unpack(&#39;&gt;i&#39;,self._filehandle.read(4))[0]

                # Check Fortran header and trailer for the record.
                if fortran_header != fortran_trailer:
                    raise IOError(&#39;Bad Fortran record.&#39;)

                # NOTE: The &#39;offset&#39; key contains the byte position in the file of where
                # data record begins. A value of 12 is added to consider a 4-byte Fortran
                # header, 4-byte &#34;trash&#34;, and 4-byte ioctet value (already) stored on index.
                self._index[&#39;offset&#39;].append(pos+12) # 4-byte header + 4-byte trash + 4-byte ioctet

                # Hold the record number of the last station ID record
                if self._index[&#39;type&#39;][-1] == &#39;station&#39;:
                    _last_station_id_record = self.records # This should be OK.

            except(struct.error):
                self._filehandle.seek(0)
                break

        self._hasindex = True
        self.dates = tuple(sorted(set(self._index[&#39;date&#39;])))
        self.leadtimes = tuple(sorted(set(self._index[&#39;lead&#39;])))

    def close(self):
        &#34;&#34;&#34;
        Close the file handle
        &#34;&#34;&#34;
        self._filehandle.close()

    def read(self,num=None,unpack=True):
        &#34;&#34;&#34;
        Read num records from the current position.
        &#34;&#34;&#34;
        #pdb.set_trace()
        recs = []
        if num == 0:
            return recs
        elif num == 1:
            reclist = [self.recordnumber+1]
        elif num &gt; 1:
            reclist = list(range(self.recordnumber+1,self.recordnumber+1+num))
        for n in reclist:
            nn = n-1 # Use this for the self._index referencing
            kwargs = {}
            self.seek(n)
            kwargs[&#39;ioctet&#39;] = self._index[&#39;size&#39;][nn]
            kwargs[&#39;ipack&#39;] = np.frombuffer(self._filehandle.read(self._index[&#39;size&#39;][nn]),dtype=&#39;&gt;i4&#39;)
            if self._index[&#39;type&#39;][nn] == &#39;data&#39;:
                kwargs[&#39;reference_date&#39;] = self._index[&#39;date&#39;][nn]
                rec = pytdlpack.TdlpackRecord(**kwargs)
                if unpack: rec.unpack()
                recs.append(rec)
            elif self._index[&#39;type&#39;][nn] == &#39;station&#39;:
                kwargs[&#39;ipack&#39;] = kwargs[&#39;ipack&#39;].byteswap()
                rec = pytdlpack.TdlpackStationRecord(**kwargs)
                if unpack: rec.unpack()
                recs.append(rec)
            elif self._index[&#39;type&#39;][nn] == &#39;trailer&#39;:
                recs.append(pytdlpack.TdlpackTrailerRecord(**kwargs))
            self.recordnumber = n
        return recs
    
    def record(self,rec,unpack=True):
        &#34;&#34;&#34;
        Read the N-th record.
        &#34;&#34;&#34;
        #pdb.set_trace()
        if rec is None:
            return None
        if rec &lt;= 0:
            warnings.warn(&#34;Record numbers begin at 1.&#34;) 
            return None
        elif rec &gt; self.records:
            warnings.warn(&#34;Not that many records in the file.&#34;)
            return None
        else:
            self.seek(rec) # Use the actual record number here.
            return self.read(1,unpack=unpack)[0]

    def seek(self,offset):
        &#34;&#34;&#34;
        Set the position within the file in units of data records.
        &#34;&#34;&#34;
        #pdb.set_trace()
        if self._hasindex:
            if offset == 0:
                self._filehandle.seek(self._index[&#39;offset&#39;][offset])
                self.recordnumber = offset
            elif offset &gt; 0:
                self._filehandle.seek(self._index[&#39;offset&#39;][offset-1])
                self.recordnumber = offset-1
    
    def fetch(self,date=None,id=None,lead=None,unpack=True):
        &#34;&#34;&#34;
        Fetch TDLPACK data record by means of date, lead time, id or any combination
        thereof.
        &#34;&#34;&#34;
        #pdb.set_trace()
        recs = []
        idx = None
        match_count = 0

        # Match by date.
        if type(date) is not list:
           if date is None:
               date = []
           else:
               date = [date]
        if len(date) &gt; 0: match_count += 1
        for d in date:
            if d is not None:
                if idx is None:
                    idx = np.where(np.array(self._index[&#39;date&#39;])==d)[0]
                else:
                    idx = np.concatenate((idx,np.where(np.array(self._index[&#39;date&#39;])==d)[0]))

        # Match by ID.
        if id is not None:
            # Test for type
            if type(id) is str:
                # Need all 4 words for now....
                id = [int(i) for i in list(filter(None,id.split(&#39; &#39;)))]
                print(id)
            # Match by MOS ID (all 4 words)
            match_count += 4
            allrecs = np.arange(self.records)
            # ID1
            if id[0] == -1:
                idx1 = allrecs
            elif id[0] &gt;= 0:
                idx1 = np.where(np.array(self._index[&#39;id1&#39;])==id[0])[0]
            # ID2
            if id[1] == -1:
                idx2 = allrecs
            elif id[1] &gt;= 0:
                idx2 = np.where(np.array(self._index[&#39;id2&#39;])==id[1])[0]
            # ID3
            if id[2] == -1:
                idx3 = allrecs
            elif id[2] &gt;= 0:
                idx3 = np.where(np.array(self._index[&#39;id3&#39;])==id[2])[0]
            # ID4
            if id[3] == -1:
                idx4 = allrecs
            elif id[3] &gt;= 0:
                idx4 = np.where(np.array(self._index[&#39;id4&#39;])==id[3])[0]

            if idx is not None:
                idx = np.concatenate((idx,idx1,idx2,idx3,idx4))
            else:
                idx = np.concatenate((idx1,idx2,idx3,idx4))

        # Match by lead times(s).
        if type(lead) is not list:
            if lead is None:
                lead = []
            else:
                lead = [lead]
        if len(lead) &gt; 0: match_count += 1
        for l in lead:
            if l is not None:
                if idx is None:
                    idx = np.where(np.array(self._index[&#39;lead&#39;])==l)[0]
                else:
                    idx = np.concatenate((idx,np.where(np.array(self._index[&#39;lead&#39;])==l)[0]))

        # Now determine the count of unique index values.  The count needs to match the
        # value of match_count.  Where this occurs, the index values are extracted.
        vals,cnts = np.unique(idx,return_counts=True)
        idx = vals[np.where(cnts==match_count)[0]]

        # Now we iterate over the matching index values and build the list of
        # records.
        for i in idx:
            recs.append(self.record(i+1,unpack=unpack))
        return recs
    
    def tell(self):
        &#34;&#34;&#34;
        Return the position in units of records.
        &#34;&#34;&#34;
        return self.recordnumber</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="TdlpackIO.open.close"><code class="name flex">
<span>def <span class="ident">close</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Close the file handle</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def close(self):
    &#34;&#34;&#34;
    Close the file handle
    &#34;&#34;&#34;
    self._filehandle.close()</code></pre>
</details>
</dd>
<dt id="TdlpackIO.open.fetch"><code class="name flex">
<span>def <span class="ident">fetch</span></span>(<span>self, date=None, id=None, lead=None, unpack=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Fetch TDLPACK data record by means of date, lead time, id or any combination
thereof.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch(self,date=None,id=None,lead=None,unpack=True):
    &#34;&#34;&#34;
    Fetch TDLPACK data record by means of date, lead time, id or any combination
    thereof.
    &#34;&#34;&#34;
    #pdb.set_trace()
    recs = []
    idx = None
    match_count = 0

    # Match by date.
    if type(date) is not list:
       if date is None:
           date = []
       else:
           date = [date]
    if len(date) &gt; 0: match_count += 1
    for d in date:
        if d is not None:
            if idx is None:
                idx = np.where(np.array(self._index[&#39;date&#39;])==d)[0]
            else:
                idx = np.concatenate((idx,np.where(np.array(self._index[&#39;date&#39;])==d)[0]))

    # Match by ID.
    if id is not None:
        # Test for type
        if type(id) is str:
            # Need all 4 words for now....
            id = [int(i) for i in list(filter(None,id.split(&#39; &#39;)))]
            print(id)
        # Match by MOS ID (all 4 words)
        match_count += 4
        allrecs = np.arange(self.records)
        # ID1
        if id[0] == -1:
            idx1 = allrecs
        elif id[0] &gt;= 0:
            idx1 = np.where(np.array(self._index[&#39;id1&#39;])==id[0])[0]
        # ID2
        if id[1] == -1:
            idx2 = allrecs
        elif id[1] &gt;= 0:
            idx2 = np.where(np.array(self._index[&#39;id2&#39;])==id[1])[0]
        # ID3
        if id[2] == -1:
            idx3 = allrecs
        elif id[2] &gt;= 0:
            idx3 = np.where(np.array(self._index[&#39;id3&#39;])==id[2])[0]
        # ID4
        if id[3] == -1:
            idx4 = allrecs
        elif id[3] &gt;= 0:
            idx4 = np.where(np.array(self._index[&#39;id4&#39;])==id[3])[0]

        if idx is not None:
            idx = np.concatenate((idx,idx1,idx2,idx3,idx4))
        else:
            idx = np.concatenate((idx1,idx2,idx3,idx4))

    # Match by lead times(s).
    if type(lead) is not list:
        if lead is None:
            lead = []
        else:
            lead = [lead]
    if len(lead) &gt; 0: match_count += 1
    for l in lead:
        if l is not None:
            if idx is None:
                idx = np.where(np.array(self._index[&#39;lead&#39;])==l)[0]
            else:
                idx = np.concatenate((idx,np.where(np.array(self._index[&#39;lead&#39;])==l)[0]))

    # Now determine the count of unique index values.  The count needs to match the
    # value of match_count.  Where this occurs, the index values are extracted.
    vals,cnts = np.unique(idx,return_counts=True)
    idx = vals[np.where(cnts==match_count)[0]]

    # Now we iterate over the matching index values and build the list of
    # records.
    for i in idx:
        recs.append(self.record(i+1,unpack=unpack))
    return recs</code></pre>
</details>
</dd>
<dt id="TdlpackIO.open.read"><code class="name flex">
<span>def <span class="ident">read</span></span>(<span>self, num=None, unpack=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Read num records from the current position.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read(self,num=None,unpack=True):
    &#34;&#34;&#34;
    Read num records from the current position.
    &#34;&#34;&#34;
    #pdb.set_trace()
    recs = []
    if num == 0:
        return recs
    elif num == 1:
        reclist = [self.recordnumber+1]
    elif num &gt; 1:
        reclist = list(range(self.recordnumber+1,self.recordnumber+1+num))
    for n in reclist:
        nn = n-1 # Use this for the self._index referencing
        kwargs = {}
        self.seek(n)
        kwargs[&#39;ioctet&#39;] = self._index[&#39;size&#39;][nn]
        kwargs[&#39;ipack&#39;] = np.frombuffer(self._filehandle.read(self._index[&#39;size&#39;][nn]),dtype=&#39;&gt;i4&#39;)
        if self._index[&#39;type&#39;][nn] == &#39;data&#39;:
            kwargs[&#39;reference_date&#39;] = self._index[&#39;date&#39;][nn]
            rec = pytdlpack.TdlpackRecord(**kwargs)
            if unpack: rec.unpack()
            recs.append(rec)
        elif self._index[&#39;type&#39;][nn] == &#39;station&#39;:
            kwargs[&#39;ipack&#39;] = kwargs[&#39;ipack&#39;].byteswap()
            rec = pytdlpack.TdlpackStationRecord(**kwargs)
            if unpack: rec.unpack()
            recs.append(rec)
        elif self._index[&#39;type&#39;][nn] == &#39;trailer&#39;:
            recs.append(pytdlpack.TdlpackTrailerRecord(**kwargs))
        self.recordnumber = n
    return recs</code></pre>
</details>
</dd>
<dt id="TdlpackIO.open.record"><code class="name flex">
<span>def <span class="ident">record</span></span>(<span>self, rec, unpack=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Read the N-th record.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def record(self,rec,unpack=True):
    &#34;&#34;&#34;
    Read the N-th record.
    &#34;&#34;&#34;
    #pdb.set_trace()
    if rec is None:
        return None
    if rec &lt;= 0:
        warnings.warn(&#34;Record numbers begin at 1.&#34;) 
        return None
    elif rec &gt; self.records:
        warnings.warn(&#34;Not that many records in the file.&#34;)
        return None
    else:
        self.seek(rec) # Use the actual record number here.
        return self.read(1,unpack=unpack)[0]</code></pre>
</details>
</dd>
<dt id="TdlpackIO.open.seek"><code class="name flex">
<span>def <span class="ident">seek</span></span>(<span>self, offset)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the position within the file in units of data records.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def seek(self,offset):
    &#34;&#34;&#34;
    Set the position within the file in units of data records.
    &#34;&#34;&#34;
    #pdb.set_trace()
    if self._hasindex:
        if offset == 0:
            self._filehandle.seek(self._index[&#39;offset&#39;][offset])
            self.recordnumber = offset
        elif offset &gt; 0:
            self._filehandle.seek(self._index[&#39;offset&#39;][offset-1])
            self.recordnumber = offset-1</code></pre>
</details>
</dd>
<dt id="TdlpackIO.open.tell"><code class="name flex">
<span>def <span class="ident">tell</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the position in units of records.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tell(self):
    &#34;&#34;&#34;
    Return the position in units of records.
    &#34;&#34;&#34;
    return self.recordnumber</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="TdlpackIO.open" href="#TdlpackIO.open">open</a></code></h4>
<ul class="two-column">
<li><code><a title="TdlpackIO.open.close" href="#TdlpackIO.open.close">close</a></code></li>
<li><code><a title="TdlpackIO.open.fetch" href="#TdlpackIO.open.fetch">fetch</a></code></li>
<li><code><a title="TdlpackIO.open.read" href="#TdlpackIO.open.read">read</a></code></li>
<li><code><a title="TdlpackIO.open.record" href="#TdlpackIO.open.record">record</a></code></li>
<li><code><a title="TdlpackIO.open.seek" href="#TdlpackIO.open.seek">seek</a></code></li>
<li><code><a title="TdlpackIO.open.tell" href="#TdlpackIO.open.tell">tell</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>
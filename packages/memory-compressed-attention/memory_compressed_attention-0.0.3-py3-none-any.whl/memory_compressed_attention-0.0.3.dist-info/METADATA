Metadata-Version: 2.1
Name: memory-compressed-attention
Version: 0.0.3
Summary: Memory-Compressed Self Attention
Home-page: https://github.com/lucidrains/memory-compressed-attention
Author: Phil Wang
Author-email: lucidrains@gmail.com
License: MIT
Keywords: transformers,artificial intelligence,attention mechanism
Platform: UNKNOWN
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3.6
Requires-Dist: torch

UNKNOWN



<p>Summary of evaluation metrics obtained by submitting predictions by different models on the SQuAD hold-out set on SQuAD website:</p>
<table>
<colgroup>
<col style="width: 6%" />
<col style="width: 8%" />
<col style="width: 7%" />
<col style="width: 3%" />
<col style="width: 6%" />
<col style="width: 12%" />
<col style="width: 10%" />
<col style="width: 12%" />
<col style="width: 12%" />
<col style="width: 9%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr class="header">
<th>MODEL</th>
<th>finetuned</th>
<th>exact</th>
<th>f1</th>
<th>total</th>
<th>HasAns_exact</th>
<th>HasAns_f1</th>
<th>HasAns_total</th>
<th>NoAns_exact</th>
<th>NoAns_f1</th>
<th>NoAns_total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>human performance</td>
<td>NA</td>
<td>86.831</td>
<td>89.452</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr class="even">
<td>albert-base-v2</td>
<td>NA</td>
<td>18.38</td>
<td>19.13</td>
<td>11873</td>
<td>0.05</td>
<td>1.55</td>
<td>5928</td>
<td>36.65</td>
<td>36.65</td>
<td>5945</td>
</tr>
<tr class="odd">
<td>albert-xxlarge-v2</td>
<td>NA</td>
<td>0.008</td>
<td>0.64</td>
<td>11873</td>
<td>0</td>
<td>1.26</td>
<td>5928</td>
<td>0.017</td>
<td>0.017</td>
<td>5945</td>
</tr>
<tr class="even">
<td>bert_base_uncased</td>
<td>squad</td>
<td>25.16</td>
<td>26.22</td>
<td>11873</td>
<td>0.84</td>
<td>2.96</td>
<td>5928</td>
<td>49.4</td>
<td>49.4</td>
<td>5945</td>
</tr>
<tr class="odd">
<td>distilbert-ba</td>
<td>Travis</td>
<td>56.77</td>
<td>59.17</td>
<td>11873</td>
<td>46.27</td>
<td>51.07</td>
<td>5928</td>
<td>67.24</td>
<td>67.24</td>
<td>5945</td>
</tr>
<tr class="even">
<td>bert-ba</td>
<td>Travis</td>
<td>62.58</td>
<td>65.52</td>
<td>11873</td>
<td>48.98</td>
<td>54.87</td>
<td>5928</td>
<td>76.14</td>
<td>76.14</td>
<td>5945</td>
</tr>
<tr class="odd">
<td>albert-lg</td>
<td>Travis</td>
<td>63.56</td>
<td>65.12</td>
<td>11873</td>
<td>34.90</td>
<td>38.03</td>
<td>5928</td>
<td>92.14</td>
<td>92.1</td>
<td>5945</td>
</tr>
<tr class="even">
<td>bert-tiny</td>
<td>mrm8488, squad2</td>
<td>35.11</td>
<td>35.11</td>
<td>11873</td>
<td>0.15</td>
<td>0.34</td>
<td>5928</td>
<td>69.97</td>
<td>69.97</td>
<td>5945</td>
</tr>
<tr class="odd">
<td>albert-base-v2</td>
<td>twmkn9, squad2</td>
<td>77.92</td>
<td>81.38</td>
<td>11873</td>
<td>72.84</td>
<td>79.78</td>
<td>5928</td>
<td>82.98</td>
<td>82.98</td>
<td>5945</td>
</tr>
<tr class="even">
<td>albert-xlarge-v2</td>
<td>ktrapeznikov, squad2</td>
<td>84.46</td>
<td>87.47</td>
<td>11873</td>
<td>80.01</td>
<td>86.04</td>
<td>5928</td>
<td>88.90</td>
<td>88.90</td>
<td>5945</td>
</tr>
</tbody>
</table>
